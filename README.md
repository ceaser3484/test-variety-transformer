# test-variety-transformer

개인적으로 프로젝트 시작..
### Linformer

- 훈련 속도가 빠르다고 알려진 Linformer(https://arxiv.org/pdf/2006.04768)를 분석하여 코딩..
- 기존의 Transformer(https://arxiv.org/abs/1706.03762)에서 self-attnetion은 softmax(Q @ K) @ V 이지만 sentence가 길어질 수록 self-attention에 큰 연산을 요구함.
- 그리고 큰 연산을 요구하기에 훈련 시간도 많이 걸림..
- 그래서 .... (설명을 더 적어야 함..)
- 집에서 작은 LLM을 만들고 싶어서 다음 프로젝트를 시작...


#### LLM 